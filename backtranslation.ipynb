{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(chrome_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(t, driver):\n",
    "    new_text = []\n",
    "    lang = [\"ko\", 'ja&hn=0']\n",
    "    for l in lang:\n",
    "        backtrans = \"\"\n",
    "        try:\n",
    "            driver.get('https://papago.naver.com/?sk=en&tk='+l+'&st='+t)\n",
    "            time.sleep(2.5)\n",
    "            backtrans = driver.find_element_by_xpath('//*[@id=\"txtTarget\"]').text\n",
    "        except:\n",
    "            pass\n",
    "        if backtrans != \"\":\n",
    "            return_sen = \"\"\n",
    "            try:\n",
    "                driver.get('https://papago.naver.com/?sk='+l+'&tk=en&st='+backtrans)\n",
    "                time.sleep(2.5)\n",
    "                return_sen = driver.find_element_by_xpath('//*[@id=\"txtTarget\"]').text\n",
    "            except:\n",
    "                pass\n",
    "            if return_sen != \"\":\n",
    "                new_text.append(return_sen)\n",
    "    return list(set(new_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrans_total(driver):\n",
    "    train = pd.read_csv(\"./data/train.csv\")\n",
    "    val = train[\"label\"].values.tolist()\n",
    "    val = list(set(val))\n",
    "\n",
    "    aug_label = []\n",
    "    for v in val:\n",
    "        if len(train[train[\"label\"] == v]) < 1000:\n",
    "            aug_label.append(v)\n",
    "\n",
    "    aug_data = pd.DataFrame()\n",
    "    for idx in tqdm(range(len(train))):\n",
    "        original = train.iloc[idx]\n",
    "        if original[\"label\"] in aug_label:\n",
    "            new_text = trans(original[\"문장\"], driver)\n",
    "            for n in new_text:\n",
    "                if original[\"문장\"] != n:\n",
    "                    add = pd.DataFrame([{\n",
    "                        \"ID\" : original[\"ID\"],\n",
    "                        \"문장\": n,\n",
    "                        \"유형\": original[\"유형\"],\n",
    "                        \"극성\": original[\"극성\"],\n",
    "                        \"시제\": original[\"시제\"],\n",
    "                        \"확실성\": original[\"확실성\"],\n",
    "                        \"label\": original[\"label\"]\n",
    "                    }])\n",
    "                    aug_data = aug_data.append(add)\n",
    "\n",
    "    train = train.append(aug_data)\n",
    "    train.to_csv(\"./data/train_totalaug.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16541/16541 [10:14:16<00:00,  2.23s/it] \n"
     ]
    }
   ],
   "source": [
    "backtrans_total(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtranslation(driver):\n",
    "    train = pd.read_csv(\"./data/train.csv\")\n",
    "    train.drop([\"극성\", \"시제\", \"확실성\", \"label\"], axis=1)\n",
    "\n",
    "    aug_label = [\"추론형\", \"대화형\", \"예측형\"]\n",
    "    aug_data = pd.DataFrame()\n",
    "    for a in tqdm(aug_label):\n",
    "        aug_data = aug_data.append(train[train[\"유형\"] == a])\n",
    "    \n",
    "    auged_data = pd.DataFrame()\n",
    "    for idx in tqdm(range(len(aug_data))):\n",
    "        original = aug_data.iloc[idx]\n",
    "        new_text = trans(original[\"문장\"], driver)\n",
    "        for n in new_text:\n",
    "            if original[\"문장\"] != n:\n",
    "                add = pd.DataFrame([{\n",
    "                    \"ID\" : original[\"ID\"],\n",
    "                    \"문장\" : n,\n",
    "                    \"유형\" : original[\"유형\"],\n",
    "                }])\n",
    "                auged_data = auged_data.append(add)\n",
    "    train = train.append(auged_data)\n",
    "    train.to_csv(\"./data/train_backtrans_0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 129.37it/s]\n",
      "100%|██████████| 2983/2983 [8:39:40<00:00, 10.45s/it]  \n"
     ]
    }
   ],
   "source": [
    "backtranslation(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 극성\n",
    "def backtranslation_1(driver):\n",
    "    train = pd.read_csv(\"./data/train.csv\")\n",
    "    train.drop([\"유형\", \"시제\", \"확실성\", \"label\"], axis=1)\n",
    "\n",
    "    aug_label = [\"부정\", \"미정\"]\n",
    "    aug_data = pd.DataFrame()\n",
    "    for a in tqdm(aug_label):\n",
    "        aug_data = aug_data.append(train[train[\"극성\"] == a])\n",
    "    \n",
    "    auged_data = pd.DataFrame()\n",
    "    for idx in tqdm(range(len(aug_data))):\n",
    "        original = aug_data.iloc[idx]\n",
    "        new_text = trans(original[\"문장\"], driver)\n",
    "        for n in new_text:\n",
    "            if original[\"문장\"] != n:\n",
    "                add = pd.DataFrame([{\n",
    "                    \"ID\" : original[\"ID\"],\n",
    "                    \"문장\" : n,\n",
    "                    \"극성\" : original[\"극성\"],\n",
    "                }])\n",
    "                auged_data = auged_data.append(add)\n",
    "    train = train.append(auged_data)\n",
    "    train.to_csv(\"./data/train_backtrans_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 65.61it/s]\n",
      "100%|██████████| 748/748 [2:10:18<00:00, 10.45s/it]  \n"
     ]
    }
   ],
   "source": [
    "backtranslation_1(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시제\n",
    "def backtranslation_2(driver):\n",
    "    train = pd.read_csv(\"./data/train.csv\")\n",
    "    train.drop([\"유형\", \"극성\", \"확실성\", \"label\"], axis=1)\n",
    "\n",
    "    aug_label = [\"미래\"]\n",
    "    aug_data = pd.DataFrame()\n",
    "    for a in tqdm(aug_label):\n",
    "        aug_data = aug_data.append(train[train[\"시제\"] == a])\n",
    "    \n",
    "    auged_data = pd.DataFrame()\n",
    "    for idx in tqdm(range(len(aug_data))):\n",
    "        original = aug_data.iloc[idx]\n",
    "        new_text = trans(original[\"문장\"], driver)\n",
    "        for n in new_text:\n",
    "            if original[\"문장\"] != n:\n",
    "                add = pd.DataFrame([{\n",
    "                    \"ID\" : original[\"ID\"],\n",
    "                    \"문장\" : n,\n",
    "                    \"시제\" : original[\"시제\"],\n",
    "                }])\n",
    "                auged_data = auged_data.append(add)\n",
    "    train = train.append(auged_data)\n",
    "    train.to_csv(\"./data/train_backtrans_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 226.25it/s]\n",
      "100%|██████████| 1643/1643 [4:45:49<00:00, 10.44s/it]  \n"
     ]
    }
   ],
   "source": [
    "backtranslation_2(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확실성\n",
    "def backtranslation_3(driver):\n",
    "    train = pd.read_csv(\"./data/train.csv\")\n",
    "    train.drop([\"유형\", \"극성\", \"시제\", \"label\"], axis=1)\n",
    "\n",
    "    aug_label = [\"불확실\"]\n",
    "    aug_data = pd.DataFrame()\n",
    "    for a in tqdm(aug_label):\n",
    "        aug_data = aug_data.append(train[train[\"확실성\"] == a])\n",
    "    \n",
    "    auged_data = pd.DataFrame()\n",
    "    for idx in tqdm(range(len(aug_data))):\n",
    "        original = aug_data.iloc[idx]\n",
    "        new_text = trans(original[\"문장\"], driver)\n",
    "        for n in new_text:\n",
    "            if original[\"문장\"] != n:\n",
    "                add = pd.DataFrame([{\n",
    "                    \"ID\" : original[\"ID\"],\n",
    "                    \"문장\" : n,\n",
    "                    \"확실성\" : original[\"확실성\"],\n",
    "                }])\n",
    "                auged_data = auged_data.append(add)\n",
    "    train = train.append(auged_data)\n",
    "    train.to_csv(\"./data/train_backtrans_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtranslation_3(driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
